{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eae86f7",
   "metadata": {},
   "source": [
    "# 02 - ML Experimentation with Custom Model\n",
    "\n",
    "The purpose of this notebook is to use [custom training](https://cloud.google.com/ai-platform-unified/docs/training/custom-training) to train a keras classifier to predict whether a given trip will result in a tip > 20%. The notebook covers the following tasks:\n",
    "1. Preprocess the data locally using Apache Beam.\n",
    "2. Submit a Dataflow job to preprocess the data at scale.\n",
    "3. Submit a custom training job to Vertex AI using a [pre-built container](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers).\n",
    "4. Upload the trained model to Vertex AI.\n",
    "5. Track experiment parameters from [Vertex AI Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction).\n",
    "6. Submit a [hyperparameter tuning job](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview) to Vertex AI.\n",
    "\n",
    "We use [Vertex TensorBoard](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) \n",
    "and [Vertex ML Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction) to  track, visualize, and compare ML experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5205917",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c6cfe",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903522d2-f858-4dda-b0e2-bd0ffa6611cf",
   "metadata": {},
   "source": [
    "The **preprocessing** step has been implemented in 'src/preprocessing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4171d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 12:54:57.508230: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.typehints.native_type_compatibility:Using Any for unsupported type: typing.Sequence[~T]\n",
      "TensorFlow: 2.5.3\n",
      "TensorFlow Transform: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hp_tuning\n",
    "\n",
    "from src.common import features, datasource_utils\n",
    "from src.model_training import data, model, defaults, trainer, exporter\n",
    "from src.preprocessing import etl\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"TensorFlow Transform: {tft.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde361cf",
   "metadata": {},
   "source": [
    "### Setup Google Cloud project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae12c9-1db2-4f69-8677-6467bd755abf",
   "metadata": {},
   "source": [
    "When not explicitly provided, Vertex AI relies on the **Compute Engine default SA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fce242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: grandelli-demo-295810\n",
      "Region: us-central1\n",
      "Bucket name: grandelli-demo-295810-partner-training-2022\n",
      "Service Account: 155283586619-compute@developer.gserviceaccount.com\n",
      "Vertex API Parent URI: projects/grandelli-demo-295810/locations/us-central1\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'grandelli-demo-295810' # Change to your project id.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "BUCKET = 'grandelli-demo-295810-partner-training-2022' # Change to your bucket name.\n",
    "SERVICE_ACCOUNT = \"155283586619-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "if PROJECT == \"\" or PROJECT is None or PROJECT == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT = shell_output[0]\n",
    "    \n",
    "if SERVICE_ACCOUNT == \"\" or SERVICE_ACCOUNT is None or SERVICE_ACCOUNT == \"[your-service-account]\":\n",
    "    # Get your GCP account from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.account)' 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"[your-bucket-name]\":\n",
    "    # Get your bucket name to GCP projet id\n",
    "    BUCKET = PROJECT\n",
    "    # Try to create the bucket if it doesn'exists\n",
    "    ! gsutil mb -l $REGION gs://$BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "PARENT = f\"projects/{PROJECT}/locations/{REGION}\"\n",
    "    \n",
    "print(\"Project ID:\", PROJECT)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)\n",
    "print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "print(\"Vertex API Parent URI:\", PARENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cfd33f",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b363e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v01'\n",
    "DATASET_DISPLAY_NAME = 'chicago-taxi-tips'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "\n",
    "WORKSPACE = f'gs://{BUCKET}/{DATASET_DISPLAY_NAME}'\n",
    "EXPERIMENT_ARTIFACTS_DIR = os.path.join(WORKSPACE, 'experiments')\n",
    "RAW_SCHEMA_LOCATION = 'src/raw_schema/schema.pbtxt'\n",
    "\n",
    "TENSORBOARD_DISPLAY_NAME = f'tb-{DATASET_DISPLAY_NAME}'\n",
    "EXPERIMENT_NAME = f'{MODEL_DISPLAY_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf63d9",
   "metadata": {},
   "source": [
    "## Create Vertex TensorBoard instance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ccfe89-97a5-4277-a58a-3c2050d63b75",
   "metadata": {},
   "source": [
    "While the open source TensorBoard (TB) is a Google open source project for machine learning experiment visualization, **Vertex AI TensorBoard** is an enterprise-ready managed version of TensorBoard.\n",
    "\n",
    "If you are using custom training to train models, you can set up your training job to automatically upload your Vertex AI TensorBoard logs to Vertex AI TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf8ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:55:06.655858338       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard:Creating Tensorboard\n",
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard:Create Tensorboard backing LRO: projects/155283586619/locations/us-central1/tensorboards/1155824215304175616/operations/6348477403160903680\n",
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard:Tensorboard created. Resource name: projects/155283586619/locations/us-central1/tensorboards/1155824215304175616\n",
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard:To use this Tensorboard in another session:\n",
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard:tb = aiplatform.Tensorboard('projects/155283586619/locations/us-central1/tensorboards/1155824215304175616')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:55:18.089779084       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:55:19.889699529       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard resource name: projects/155283586619/locations/us-central1/tensorboards/1155824215304175616\n"
     ]
    }
   ],
   "source": [
    "tensorboard_resource = vertex_ai.Tensorboard.create(display_name=TENSORBOARD_DISPLAY_NAME)\n",
    "tensorboard_resource_name = tensorboard_resource.gca_resource.name\n",
    "print(\"TensorBoard resource name:\", tensorboard_resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a3859",
   "metadata": {},
   "source": [
    "## Initialize workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d03fba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace is ready.\n",
      "Experiment directory: gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments\n"
     ]
    }
   ],
   "source": [
    "REMOVE_EXPERIMENT_ARTIFACTS = False\n",
    "\n",
    "if tf.io.gfile.exists(EXPERIMENT_ARTIFACTS_DIR) and REMOVE_EXPERIMENT_ARTIFACTS:\n",
    "    print(\"Removing previous experiment artifacts...\")\n",
    "    tf.io.gfile.rmtree(EXPERIMENT_ARTIFACTS_DIR)\n",
    "\n",
    "if not tf.io.gfile.exists(EXPERIMENT_ARTIFACTS_DIR):\n",
    "    print(\"Creating new experiment artifacts directory...\")\n",
    "    tf.io.gfile.mkdir(EXPERIMENT_ARTIFACTS_DIR)\n",
    "\n",
    "print(\"Workspace is ready.\")\n",
    "print(\"Experiment directory:\", EXPERIMENT_ARTIFACTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec2080",
   "metadata": {},
   "source": [
    "## Start a new Vertex AI experiment run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31c8ee-3fbf-425c-a7e9-1c6de047f7d7",
   "metadata": {},
   "source": [
    "We create an experiment in the Vertex AI init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d87d0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:55:57.346762977       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:55:59.366486037       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:56:01.309959495       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Resource chicago-taxi-tips-classifier-v01-run-gcp-20220330125601 not found.\n",
      "INFO:root:Creating Resource chicago-taxi-tips-classifier-v01-run-gcp-20220330125601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:56:03.360008584       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:56:05.451635677       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:56:07.436685222       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Resource chicago-taxi-tips-classifier-v01-run-gcp-20220330125601-metrics not found.\n",
      "INFO:root:Creating Resource chicago-taxi-tips-classifier-v01-run-gcp-20220330125601-metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:56:09.367806410       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:56:11.423364340       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run directory: gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601\n"
     ]
    }
   ],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    staging_bucket=BUCKET,\n",
    "    experiment=EXPERIMENT_NAME)\n",
    "\n",
    "run_id = f\"run-gcp-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "vertex_ai.start_run(run_id) # this will store the experiment\n",
    "\n",
    "EXPERIMENT_RUN_DIR = os.path.join(EXPERIMENT_ARTIFACTS_DIR, EXPERIMENT_NAME, run_id)\n",
    "print(\"Experiment run directory:\", EXPERIMENT_RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade27b7",
   "metadata": {},
   "source": [
    "## 3. Submit a Data Processing Job to Dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d903ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_DATA_PREFIX = os.path.join(EXPERIMENT_RUN_DIR, 'exported_data')\n",
    "TRANSFORMED_DATA_PREFIX = os.path.join(EXPERIMENT_RUN_DIR, 'transformed_data')\n",
    "TRANSFORM_ARTIFACTS_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'transform_artifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237a995-de8f-4a5d-a1ae-2c1f37655602",
   "metadata": {},
   "source": [
    "We use some BQ util functions defined in 'src/common'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fac3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:56:24.959175874       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:56:26.811459095       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "ML_USE = 'UNASSIGNED'\n",
    "LIMIT = 1000000\n",
    "raw_data_query = datasource_utils.get_training_source_query(\n",
    "    project=PROJECT, \n",
    "    region=REGION, \n",
    "    dataset_display_name=DATASET_DISPLAY_NAME, \n",
    "    ml_use=ML_USE, \n",
    "    limit=LIMIT\n",
    ")\n",
    "\n",
    "etl_job_name = f\"etl-{MODEL_DISPLAY_NAME}-{run_id}\"\n",
    "\n",
    "args = {\n",
    "    'job_name': etl_job_name,\n",
    "    'runner': 'DataflowRunner',\n",
    "    'raw_data_query': raw_data_query,\n",
    "    'exported_data_prefix': EXPORTED_DATA_PREFIX,\n",
    "    'transformed_data_prefix': TRANSFORMED_DATA_PREFIX,\n",
    "    'transform_artifact_dir': TRANSFORM_ARTIFACTS_DIR,\n",
    "    'write_raw_data': False,\n",
    "    'temporary_dir': os.path.join(WORKSPACE, 'tmp'),\n",
    "    'gcs_location': os.path.join(WORKSPACE, 'bq_tmp'),\n",
    "    'project': PROJECT,\n",
    "    'region': REGION,\n",
    "    'setup_file': './setup.py'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da745d07-5b32-4d78-9634-0b3112259349",
   "metadata": {},
   "source": [
    "This is how you can log parameters related to an experiment. https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_get_experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c909d3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:56:28.968112749       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:56:30.973634260       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "vertex_ai.log_params(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42098812-dbd6-4559-8766-54847a40e515",
   "metadata": {},
   "source": [
    "We use three components: Apache Beam (running on Dataflow), [TF Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started), [TF Transform](https://www.tensorflow.org/tfx/transform/get_started)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "014e5512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing started...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2395: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:261: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:261: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 12:56:38.324586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-03-30 12:56:38.324638: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-30 12:56:38.324673: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vm-508f776f-5512-42a9-b529-8989959ded1b): /proc/driver/nvidia/version does not exist\n",
      "2022-03-30 12:56:38.324974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0330 12:56:43.777561245       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 12:56:53.387389: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-30 12:56:53.388307: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 12:57:02.076690102       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "E0330 12:57:02.660253698       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:57:05.360688289       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:57:11.248496124       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 12:57:13.022598060       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "print(\"Data preprocessing started...\")\n",
    "etl.run_transform_pipeline(args)\n",
    "print(\"Data preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a21c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:01:12.585079433       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/\n",
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/transform_artifacts/\n",
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/transformed_data/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {EXPERIMENT_RUN_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4dfa8",
   "metadata": {},
   "source": [
    "## 4. Submit a Custom Training Job to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50db6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'logs')\n",
    "EXPORT_DIR = os.path.join(EXPERIMENT_RUN_DIR, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077e9d4",
   "metadata": {},
   "source": [
    "### Prepare training package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9c6b1-a33e-4459-891e-05f952923286",
   "metadata": {},
   "source": [
    "You can train custom models using a custom Python script, custom Python package, or container. We go for **Python package**.\n",
    "\n",
    "Please note that the model has been already developed by someone else (data scientist) and it's not at all related to Vertex AI or pipelines. The model is based on TensorFlow and stored in 'src/model_training'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d526a189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer package upload location: gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/trainer_packages\n"
     ]
    }
   ],
   "source": [
    "TRAINER_PACKAGE_DIR = os.path.join(WORKSPACE, 'trainer_packages')\n",
    "TRAINER_PACKAGE_NAME = f'{MODEL_DISPLAY_NAME}_trainer'\n",
    "print(\"Trainer package upload location:\", TRAINER_PACKAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "550cc9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:01:27.652485116       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:01:28.765200982       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'src/.ipynb_checkpoints/': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:01:29.844955263       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'src/raw_schema/.ipynb_checkpoints/': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:01:30.899875023       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:01:31.972771395       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:01:33.316606690       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:01:34.519262214       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:01:35.966238915       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicago-taxi-tips-classifier-v01_trainer/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/raw_schema/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/raw_schema/schema.pbtxt\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/pipeline_triggering/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/pipeline_triggering/main.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/pipeline_triggering/requirements.txt\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/pipeline_triggering/__init__.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/runner.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/config.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__pycache__/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__pycache__/config.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__pycache__/training_pipeline.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__pycache__/__init__.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__pycache__/components.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__pycache__/runner.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__pycache__/prediction_pipeline.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/training_pipeline.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/.ipynb_checkpoints/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/.ipynb_checkpoints/components-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/__init__.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/components.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tfx_pipelines/prediction_pipeline.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/etl.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/transformations.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/__pycache__/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/__pycache__/__init__.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/__pycache__/transformations.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/__pycache__/etl.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/.ipynb_checkpoints/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/.ipynb_checkpoints/etl-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/preprocessing/__init__.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/datasource_utils.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/__pycache__/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/__pycache__/datasource_utils.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/__pycache__/__init__.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/__pycache__/features.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/features.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/.ipynb_checkpoints/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/.ipynb_checkpoints/datasource_utils-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/common/__init__.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/etl_tests.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/datasource_utils_tests.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/__pycache__/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/__pycache__/__init__.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/__pycache__/pipeline_deployment_tests.cpython-37-pytest-7.1.0.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/__pycache__/model_deployment_tests.cpython-37-pytest-7.1.0.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/__pycache__/model_tests.cpython-37-pytest-7.1.0.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/__pycache__/datasource_utils_tests.cpython-37-pytest-7.1.0.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/.ipynb_checkpoints/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/.ipynb_checkpoints/model_deployment_tests-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/model_tests.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/model_deployment_tests.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/pipeline_deployment_tests.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/tests/__init__.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/runner.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/data.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/exporter.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/data.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/task.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/exporter.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/defaults.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/__init__.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/trainer.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__pycache__/model.cpython-37.pyc\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/task-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/defaults-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/exporter-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/model-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/runner-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/trainer-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/.ipynb_checkpoints/__init__-checkpoint.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/model.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/task.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/trainer.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/defaults.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/model_training/__init__.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/src/__init__.py\n",
      "chicago-taxi-tips-classifier-v01_trainer/setup.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:01:37.121740128       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:01:38.233388048       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://chicago-taxi-tips-classifier-v01_trainer.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][ 44.3 KiB/ 44.3 KiB]                                                \n",
      "Operation completed over 1 objects/44.3 KiB.                                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:01:42.789543388       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:01:43.888697767       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "!rm -r src/__pycache__/\n",
    "!rm -r src/.ipynb_checkpoints/\n",
    "!rm -r src/raw_schema/.ipynb_checkpoints/\n",
    "!rm -f {TRAINER_PACKAGE_NAME}.tar {TRAINER_PACKAGE_NAME}.tar.gz\n",
    "\n",
    "!mkdir {TRAINER_PACKAGE_NAME}\n",
    "\n",
    "!cp setup.py {TRAINER_PACKAGE_NAME}/\n",
    "!cp -r src {TRAINER_PACKAGE_NAME}/\n",
    "!tar cvf {TRAINER_PACKAGE_NAME}.tar {TRAINER_PACKAGE_NAME}\n",
    "!gzip {TRAINER_PACKAGE_NAME}.tar\n",
    "!gsutil cp {TRAINER_PACKAGE_NAME}.tar.gz {TRAINER_PACKAGE_DIR}/\n",
    "!rm -r {TRAINER_PACKAGE_NAME}\n",
    "!rm -r {TRAINER_PACKAGE_NAME}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3af757",
   "metadata": {},
   "source": [
    "### Prepare the training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d6271b-af1b-4c7e-9dc3-7d0896df3436",
   "metadata": {},
   "source": [
    "We use a pre-built image running on CPU only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e01bf43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image: us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-5:latest\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RUNTIME = 'tf-cpu.2-5'\n",
    "TRAIN_IMAGE = f\"us-docker.pkg.dev/vertex-ai/training/{TRAIN_RUNTIME}:latest\"\n",
    "print(\"Training image:\", TRAIN_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d18dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "hidden_units = \"64,64\"\n",
    "\n",
    "trainer_args = [\n",
    "    f'--train-data-dir={TRANSFORMED_DATA_PREFIX + \"/train/*\"}',\n",
    "    f'--eval-data-dir={TRANSFORMED_DATA_PREFIX + \"/eval/*\"}',\n",
    "    f'--tft-output-dir={TRANSFORM_ARTIFACTS_DIR}',\n",
    "    f'--num-epochs={num_epochs}',\n",
    "    f'--learning-rate={learning_rate}',\n",
    "    f'--project={PROJECT}',\n",
    "    f'--region={REGION}',\n",
    "    f'--staging-bucket={BUCKET}',\n",
    "    f'--experiment-name={EXPERIMENT_NAME}'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10e286-7184-4971-9d42-1ac5f661c0a3",
   "metadata": {},
   "source": [
    "Here we specify the Python training module to execute and we specify the HW configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a30d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "package_uri = os.path.join(TRAINER_PACKAGE_DIR, f'{TRAINER_PACKAGE_NAME}.tar.gz')\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": 'n1-standard-4',\n",
    "            \"accelerator_count\": 0\n",
    "    },\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": [package_uri],\n",
    "            \"python_module\": \"src.model_training.task\",\n",
    "            \"args\": trainer_args,\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d6e99",
   "metadata": {},
   "source": [
    "### Submit the training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489eb74-0b8b-4665-b634-862d10632f2a",
   "metadata": {},
   "source": [
    "Inside the trainer code we've specified how to save the created model (in a GCS folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4544105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting a custom training job...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:01:53.642137538       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "print(\"Submitting a custom training job...\")\n",
    "\n",
    "training_job_display_name = f\"{TRAINER_PACKAGE_NAME}_{run_id}\"\n",
    "\n",
    "training_job = vertex_ai.CustomJob(\n",
    "    display_name=training_job_display_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=EXPERIMENT_RUN_DIR,\n",
    ")\n",
    "\n",
    "training_job.run(\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    tensorboard=tensorboard_resource_name,\n",
    "    sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2896b59",
   "metadata": {},
   "source": [
    "## 5. Upload exported model to Vertex AI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e86b288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:12:42.874320526       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/model/\n",
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/model/keras_metadata.pb\n",
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/model/saved_model.pb\n",
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/model/assets/\n",
      "gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/model/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {EXPORT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e0c39",
   "metadata": {},
   "source": [
    "### Generate the Explanation metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3d5df4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'trip_month': {'input_tensor_name': 'trip_month',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'},\n",
       "  'trip_day': {'input_tensor_name': 'trip_day',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'},\n",
       "  'trip_day_of_week': {'input_tensor_name': 'trip_day_of_week',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'},\n",
       "  'trip_hour': {'input_tensor_name': 'trip_hour',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'},\n",
       "  'trip_seconds': {'input_tensor_name': 'trip_seconds', 'modality': 'numeric'},\n",
       "  'trip_miles': {'input_tensor_name': 'trip_miles', 'modality': 'numeric'},\n",
       "  'payment_type': {'input_tensor_name': 'payment_type',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'},\n",
       "  'pickup_grid': {'input_tensor_name': 'pickup_grid',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'},\n",
       "  'dropoff_grid': {'input_tensor_name': 'dropoff_grid',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'},\n",
       "  'euclidean': {'input_tensor_name': 'euclidean', 'modality': 'numeric'},\n",
       "  'loc_cross': {'input_tensor_name': 'loc_cross',\n",
       "   'encoding': 'IDENTITY',\n",
       "   'modality': 'categorical'}},\n",
       " 'outputs': {'scores': {'output_tensor_name': 'scores'}},\n",
       " 'params': {'sampled_shapley_attribution': {'path_count': 10}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation_config = features.generate_explanation_config()\n",
    "explanation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd0587",
   "metadata": {},
   "source": [
    "### Upload model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a8a94-237a-42da-ae17-0f82c27bbce0",
   "metadata": {},
   "source": [
    "We upload the model saved in GCS to Vertex AI. We specify the serving environment (it's typically the same of the training one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6d0dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving image: us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\n"
     ]
    }
   ],
   "source": [
    "SERVING_RUNTIME='tf2-cpu.2-5'\n",
    "SERVING_IMAGE = f\"us-docker.pkg.dev/vertex-ai/prediction/{SERVING_RUNTIME}:latest\"\n",
    "print(\"Serving image:\", SERVING_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b24abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:13:03.178516870       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:17:08.280295660       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "explanation_metadata = vertex_ai.explain.ExplanationMetadata(\n",
    "    inputs=explanation_config[\"inputs\"],\n",
    "    outputs=explanation_config[\"outputs\"],\n",
    ")\n",
    "explanation_parameters = vertex_ai.explain.ExplanationParameters(\n",
    "    explanation_config[\"params\"]\n",
    ")\n",
    "\n",
    "vertex_model = vertex_ai.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=EXPORT_DIR,\n",
    "    serving_container_image_uri=SERVING_IMAGE,\n",
    "    parameters_schema_uri=None,\n",
    "    instance_schema_uri=None,\n",
    "    explanation_metadata=explanation_metadata,\n",
    "    explanation_parameters=explanation_parameters,\n",
    "    labels={\n",
    "        'dataset_name': DATASET_DISPLAY_NAME,\n",
    "        'experiment': run_id\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51756dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/155283586619/locations/us-central1/models/2580162364250783744\"\n",
       "display_name: \"chicago-taxi-tips-classifier-v01\"\n",
       "predict_schemata {\n",
       "}\n",
       "metadata {\n",
       "}\n",
       "container_spec {\n",
       "  image_uri: \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\"\n",
       "}\n",
       "supported_deployment_resources_types: DEDICATED_RESOURCES\n",
       "supported_input_storage_formats: \"jsonl\"\n",
       "supported_input_storage_formats: \"csv\"\n",
       "supported_input_storage_formats: \"tf-record\"\n",
       "supported_input_storage_formats: \"tf-record-gzip\"\n",
       "supported_input_storage_formats: \"file-list\"\n",
       "supported_output_storage_formats: \"jsonl\"\n",
       "create_time {\n",
       "  seconds: 1648649585\n",
       "  nanos: 538720000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1648649815\n",
       "  nanos: 15556000\n",
       "}\n",
       "etag: \"AMEw9yM3N5vAkZNva6ZMHBIJn_lJj0Hfy13u6VhuPMB_2weaFi2wPj9_p7iFGlqgPwc=\"\n",
       "labels {\n",
       "  key: \"dataset_name\"\n",
       "  value: \"chicago-taxi-tips\"\n",
       "}\n",
       "labels {\n",
       "  key: \"experiment\"\n",
       "  value: \"run-gcp-20220330125601\"\n",
       "}\n",
       "supported_export_formats {\n",
       "  id: \"custom-trained\"\n",
       "  exportable_contents: ARTIFACT\n",
       "}\n",
       "explanation_spec {\n",
       "  parameters {\n",
       "    sampled_shapley_attribution {\n",
       "      path_count: 10\n",
       "    }\n",
       "  }\n",
       "  metadata {\n",
       "    inputs {\n",
       "      key: \"dropoff_grid\"\n",
       "      value {\n",
       "        input_tensor_name: \"dropoff_grid\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"euclidean\"\n",
       "      value {\n",
       "        input_tensor_name: \"euclidean\"\n",
       "        modality: \"numeric\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"loc_cross\"\n",
       "      value {\n",
       "        input_tensor_name: \"loc_cross\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"payment_type\"\n",
       "      value {\n",
       "        input_tensor_name: \"payment_type\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"pickup_grid\"\n",
       "      value {\n",
       "        input_tensor_name: \"pickup_grid\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"trip_day\"\n",
       "      value {\n",
       "        input_tensor_name: \"trip_day\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"trip_day_of_week\"\n",
       "      value {\n",
       "        input_tensor_name: \"trip_day_of_week\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"trip_hour\"\n",
       "      value {\n",
       "        input_tensor_name: \"trip_hour\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"trip_miles\"\n",
       "      value {\n",
       "        input_tensor_name: \"trip_miles\"\n",
       "        modality: \"numeric\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"trip_month\"\n",
       "      value {\n",
       "        input_tensor_name: \"trip_month\"\n",
       "        encoding: IDENTITY\n",
       "        modality: \"categorical\"\n",
       "      }\n",
       "    }\n",
       "    inputs {\n",
       "      key: \"trip_seconds\"\n",
       "      value {\n",
       "        input_tensor_name: \"trip_seconds\"\n",
       "        modality: \"numeric\"\n",
       "      }\n",
       "    }\n",
       "    outputs {\n",
       "      key: \"scores\"\n",
       "      value {\n",
       "        output_tensor_name: \"scores\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "artifact_uri: \"gs://grandelli-demo-295810-partner-training-2022/chicago-taxi-tips/experiments/chicago-taxi-tips-classifier-v01/run-gcp-20220330125601/model\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_model.gca_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa55220",
   "metadata": {},
   "source": [
    "## 6. Extract experiment run parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49412a7-638c-4285-b4cc-3f68c2a4c407",
   "metadata": {},
   "source": [
    "Again metadata, but this time related to the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07808f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:17:42.589766506       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:17:44.849559050       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:17:46.973743023       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:17:48.909385655       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0330 14:17:50.809069380       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <td>chicago-taxi-tips-classifier-v01</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01</td>\n",
       "      <td>chicago-taxi-tips-classifier-v01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_name</th>\n",
       "      <td>run-gcp-20220330140544</td>\n",
       "      <td>run-gcp-20220330125601</td>\n",
       "      <td>run-gcp-20220330125531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.model_dir</th>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.region</th>\n",
       "      <td>us-central1</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.staging_bucket</th>\n",
       "      <td>grandelli-demo-295810-partner-training-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.train_data_dir</th>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.experiment_name</th>\n",
       "      <td>chicago-taxi-tips-classifier-v01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.learning_rate</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.hidden_units</th>\n",
       "      <td>[64.0, 32.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.run_name</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.tft_output_dir</th>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.num_epochs</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.project</th>\n",
       "      <td>grandelli-demo-295810</td>\n",
       "      <td>grandelli-demo-295810</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.eval_data_dir</th>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.log_dir</th>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.batch_size</th>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.val_loss</th>\n",
       "      <td>0.256625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric.val_accuracy</th>\n",
       "      <td>0.884002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.temporary_dir</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.transformed_data_prefix</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.raw_data_query</th>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n    SELECT \\n        IF(trip_month IS NULL, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.gcs_location</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.setup_file</th>\n",
       "      <td>NaN</td>\n",
       "      <td>./setup.py</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.write_raw_data</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.job_name</th>\n",
       "      <td>NaN</td>\n",
       "      <td>etl-chicago-taxi-tips-classifier-v01-run-gcp-2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.transform_artifact_dir</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.exported_data_prefix</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gs://grandelli-demo-295810-partner-training-20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.runner</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DataflowRunner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               0  \\\n",
       "experiment_name                                 chicago-taxi-tips-classifier-v01   \n",
       "run_name                                                  run-gcp-20220330140544   \n",
       "param.model_dir                gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.region                                                         us-central1   \n",
       "param.staging_bucket                 grandelli-demo-295810-partner-training-2022   \n",
       "param.train_data_dir           gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.experiment_name                           chicago-taxi-tips-classifier-v01   \n",
       "param.learning_rate                                                        0.001   \n",
       "param.hidden_units                                                  [64.0, 32.0]   \n",
       "param.run_name                                                               NaN   \n",
       "param.tft_output_dir           gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.num_epochs                                                              10   \n",
       "param.project                                              grandelli-demo-295810   \n",
       "param.eval_data_dir            gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.log_dir                  gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.batch_size                                                             512   \n",
       "metric.val_loss                                                         0.256625   \n",
       "metric.val_accuracy                                                     0.884002   \n",
       "param.temporary_dir                                                          NaN   \n",
       "param.transformed_data_prefix                                                NaN   \n",
       "param.raw_data_query                                                         NaN   \n",
       "param.gcs_location                                                           NaN   \n",
       "param.setup_file                                                             NaN   \n",
       "param.write_raw_data                                                         NaN   \n",
       "param.job_name                                                               NaN   \n",
       "param.transform_artifact_dir                                                 NaN   \n",
       "param.exported_data_prefix                                                   NaN   \n",
       "param.runner                                                                 NaN   \n",
       "\n",
       "                                                                               1  \\\n",
       "experiment_name                                 chicago-taxi-tips-classifier-v01   \n",
       "run_name                                                  run-gcp-20220330125601   \n",
       "param.model_dir                                                              NaN   \n",
       "param.region                                                         us-central1   \n",
       "param.staging_bucket                                                         NaN   \n",
       "param.train_data_dir                                                         NaN   \n",
       "param.experiment_name                                                        NaN   \n",
       "param.learning_rate                                                          NaN   \n",
       "param.hidden_units                                                           NaN   \n",
       "param.run_name                                                               NaN   \n",
       "param.tft_output_dir                                                         NaN   \n",
       "param.num_epochs                                                             NaN   \n",
       "param.project                                              grandelli-demo-295810   \n",
       "param.eval_data_dir                                                          NaN   \n",
       "param.log_dir                                                                NaN   \n",
       "param.batch_size                                                             NaN   \n",
       "metric.val_loss                                                              NaN   \n",
       "metric.val_accuracy                                                          NaN   \n",
       "param.temporary_dir            gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.transformed_data_prefix  gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.raw_data_query           \\n    SELECT \\n        IF(trip_month IS NULL, ...   \n",
       "param.gcs_location             gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.setup_file                                                      ./setup.py   \n",
       "param.write_raw_data                                                       False   \n",
       "param.job_name                 etl-chicago-taxi-tips-classifier-v01-run-gcp-2...   \n",
       "param.transform_artifact_dir   gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.exported_data_prefix     gs://grandelli-demo-295810-partner-training-20...   \n",
       "param.runner                                                      DataflowRunner   \n",
       "\n",
       "                                                              2  \n",
       "experiment_name                chicago-taxi-tips-classifier-v01  \n",
       "run_name                                 run-gcp-20220330125531  \n",
       "param.model_dir                                             NaN  \n",
       "param.region                                                NaN  \n",
       "param.staging_bucket                                        NaN  \n",
       "param.train_data_dir                                        NaN  \n",
       "param.experiment_name                                       NaN  \n",
       "param.learning_rate                                         NaN  \n",
       "param.hidden_units                                          NaN  \n",
       "param.run_name                                              NaN  \n",
       "param.tft_output_dir                                        NaN  \n",
       "param.num_epochs                                            NaN  \n",
       "param.project                                               NaN  \n",
       "param.eval_data_dir                                         NaN  \n",
       "param.log_dir                                               NaN  \n",
       "param.batch_size                                            NaN  \n",
       "metric.val_loss                                             NaN  \n",
       "metric.val_accuracy                                         NaN  \n",
       "param.temporary_dir                                         NaN  \n",
       "param.transformed_data_prefix                               NaN  \n",
       "param.raw_data_query                                        NaN  \n",
       "param.gcs_location                                          NaN  \n",
       "param.setup_file                                            NaN  \n",
       "param.write_raw_data                                        NaN  \n",
       "param.job_name                                              NaN  \n",
       "param.transform_artifact_dir                                NaN  \n",
       "param.exported_data_prefix                                  NaN  \n",
       "param.runner                                                NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_df = vertex_ai.get_experiment_df()\n",
    "experiment_df = experiment_df[experiment_df.experiment_name == EXPERIMENT_NAME]\n",
    "experiment_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "367183aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI Experiments:\n",
      "https://console.cloud.google.com/vertex-ai/locationsus-central1/experiments/chicago-taxi-tips-classifier-v01/metrics?project=grandelli-demo-295810\n"
     ]
    }
   ],
   "source": [
    "print(\"Vertex AI Experiments:\")\n",
    "print(\n",
    "    f\"https://console.cloud.google.com/vertex-ai/locations{REGION}/experiments/{EXPERIMENT_NAME}/metrics?project={PROJECT}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96618f6",
   "metadata": {},
   "source": [
    "## 7. Submit a Hyperparameter Tuning Job to Vertex AI\n",
    "\n",
    "For more information about configuring a hyperparameter study, refer to [Vertex AI Hyperparameter job configuration](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b87cd",
   "metadata": {},
   "source": [
    "### Configure a hyperparameter job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66ffa249",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_spec = {\n",
    "    'ACCURACY': 'maximize'\n",
    "}\n",
    "\n",
    "parameter_spec = {\n",
    "    'learning-rate': hp_tuning.DoubleParameterSpec(min=0.0001, max=0.01, scale='log'),\n",
    "    'hidden-units': hp_tuning.CategoricalParameterSpec(values=[\"32,32\", \"64,64\", \"128,128\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2454dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0330 14:18:25.048926947       1 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    }
   ],
   "source": [
    "tuning_job_display_name = f\"hpt_{TRAINER_PACKAGE_NAME}_{run_id}\"\n",
    "\n",
    "hp_tuning_job = vertex_ai.HyperparameterTuningJob(\n",
    "    display_name=tuning_job_display_name,\n",
    "    custom_job=training_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=4,\n",
    "    parallel_trial_count=2,\n",
    "    search_algorithm=None # Bayesian optimization.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4ee22",
   "metadata": {},
   "source": [
    "### Submit the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc5b434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting a hyperparameter tunning job...\n"
     ]
    }
   ],
   "source": [
    "print(\"Submitting a hyperparameter tunning job...\")\n",
    "\n",
    "hp_tuning_job.run(\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    tensorboard=tensorboard_resource_name,\n",
    "    restart_job_on_worker_restart=False,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd20da",
   "metadata": {},
   "source": [
    "### Retrieve trial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f8352e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"1\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"hidden-units\"\n",
       "   value {\n",
       "     string_value: \"64,64\"\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"learning-rate\"\n",
       "   value {\n",
       "     number_value: 0.0010000000000000002\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 5120\n",
       "   metrics {\n",
       "     metric_id: \"ACCURACY\"\n",
       "     value: 0.8840206861495972\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1648649922\n",
       "   nanos: 562028496\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1648650359\n",
       " },\n",
       " id: \"2\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"hidden-units\"\n",
       "   value {\n",
       "     string_value: \"128,128\"\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"learning-rate\"\n",
       "   value {\n",
       "     number_value: 0.0027540527548299987\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 5120\n",
       "   metrics {\n",
       "     metric_id: \"ACCURACY\"\n",
       "     value: 0.8848657608032227\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1648649922\n",
       "   nanos: 562176393\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1648650352\n",
       " },\n",
       " id: \"3\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"hidden-units\"\n",
       "   value {\n",
       "     string_value: \"128,128\"\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"learning-rate\"\n",
       "   value {\n",
       "     number_value: 0.000331131598752814\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 5120\n",
       "   metrics {\n",
       "     metric_id: \"ACCURACY\"\n",
       "     value: 0.8852288722991943\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1648650604\n",
       "   nanos: 342001446\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1648651062\n",
       " },\n",
       " id: \"4\"\n",
       " state: SUCCEEDED\n",
       " parameters {\n",
       "   parameter_id: \"hidden-units\"\n",
       "   value {\n",
       "     string_value: \"128,128\"\n",
       "   }\n",
       " }\n",
       " parameters {\n",
       "   parameter_id: \"learning-rate\"\n",
       "   value {\n",
       "     number_value: 0.009119487371558214\n",
       "   }\n",
       " }\n",
       " final_measurement {\n",
       "   step_count: 5120\n",
       "   metrics {\n",
       "     metric_id: \"ACCURACY\"\n",
       "     value: 0.8850660920143127\n",
       "   }\n",
       " }\n",
       " start_time {\n",
       "   seconds: 1648650604\n",
       "   nanos: 342156417\n",
       " }\n",
       " end_time {\n",
       "   seconds: 1648651037\n",
       " }]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_tuning_job.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "311922be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial ID: 3\n",
      "Validation Accuracy: 0.8852288722991943\n",
      "Hyperparameter Values:\n",
      " - hidden-units:128,128\n",
      " - learning-rate:0.000331131598752814\n"
     ]
    }
   ],
   "source": [
    "best_trial = sorted(\n",
    "    hp_tuning_job.trials, \n",
    "    key=lambda trial: trial.final_measurement.metrics[0].value, \n",
    "    reverse=True\n",
    ")[0]\n",
    "\n",
    "print(\"Best trial ID:\", best_trial.id)\n",
    "print(\"Validation Accuracy:\", best_trial.final_measurement.metrics[0].value)\n",
    "print(\"Hyperparameter Values:\")\n",
    "for parameter in best_trial.parameters:\n",
    "    print(f\" - {parameter.parameter_id}:{parameter.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88555c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:latest"
  },
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
